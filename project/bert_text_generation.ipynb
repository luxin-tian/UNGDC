{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation using BERT model\n",
    "### Luxin Tian and Heather Chen\n",
    "In this notebook we mainly utilize BERT model for text generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sklearn \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import lucem_illud_2020 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First load the corpus to a dataframe\n",
    "file_path = './raw_data/Converted sessions/'\n",
    "entry_list = []\n",
    "\n",
    "list_of_folders = os.listdir(file_path)\n",
    "for session in list_of_folders:\n",
    "    if not session.startswith('.') and 'Session' in session: \n",
    "        list_of_files = os.listdir(file_path + session)\n",
    "    else: \n",
    "        list_of_files = []\n",
    "    for country in list_of_files: \n",
    "        if not country.startswith('.') and '.txt' in country:\n",
    "            filename = country.split('.')[0].split('_')\n",
    "            country_code = filename[0]\n",
    "            session_code = filename[1]\n",
    "            year_code = filename[2]\n",
    "            text = open(file_path + session + '/' + country).read()\n",
    "            entry_list.append(pd.Series({'filename': country, \n",
    "                                         'country_code': country_code, \n",
    "                                         'session': session_code, \n",
    "                                         'year': year_code, \n",
    "                                         'text': text}))\n",
    "\n",
    "ungdc_df = pd.DataFrame(entry_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>country_code</th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BRB_73_2018.txt</td>\n",
       "      <td>BRB</td>\n",
       "      <td>73</td>\n",
       "      <td>2018</td>\n",
       "      <td>Let me begin by congratulating Ms. María Ferna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>IND_73_2018.txt</td>\n",
       "      <td>IND</td>\n",
       "      <td>73</td>\n",
       "      <td>2018</td>\n",
       "      <td>On my own behalf and on behalf of my country, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ARG_73_2018.txt</td>\n",
       "      <td>ARG</td>\n",
       "      <td>73</td>\n",
       "      <td>2018</td>\n",
       "      <td>I would like to congratulate the President on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>JOR_73_2018.txt</td>\n",
       "      <td>JOR</td>\n",
       "      <td>73</td>\n",
       "      <td>2018</td>\n",
       "      <td>It is an honour to take part in the general de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SWE_73_2018.txt</td>\n",
       "      <td>SWE</td>\n",
       "      <td>73</td>\n",
       "      <td>2018</td>\n",
       "      <td>Just a bit more than a week ago, we honoured t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8088</td>\n",
       "      <td>LIE_69_2014.txt</td>\n",
       "      <td>LIE</td>\n",
       "      <td>69</td>\n",
       "      <td>2014</td>\n",
       "      <td>This has been an \\nenormously difficult year f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8089</td>\n",
       "      <td>AZE_69_2014.txt</td>\n",
       "      <td>AZE</td>\n",
       "      <td>69</td>\n",
       "      <td>2014</td>\n",
       "      <td>At the outset, \\nI would like to congratulate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8090</td>\n",
       "      <td>GRC_69_2014.txt</td>\n",
       "      <td>GRC</td>\n",
       "      <td>69</td>\n",
       "      <td>2014</td>\n",
       "      <td>This sixty-ninth session of the General Assemb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8091</td>\n",
       "      <td>ISL_69_2014.txt</td>\n",
       "      <td>ISL</td>\n",
       "      <td>69</td>\n",
       "      <td>2014</td>\n",
       "      <td>Next year we will \\ncelebrate the seventieth a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8092</td>\n",
       "      <td>HUN_69_2014.txt</td>\n",
       "      <td>HUN</td>\n",
       "      <td>69</td>\n",
       "      <td>2014</td>\n",
       "      <td>“If you seek peace, prepare for war.” Those ar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8093 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename country_code session  year  \\\n",
       "0     BRB_73_2018.txt          BRB      73  2018   \n",
       "1     IND_73_2018.txt          IND      73  2018   \n",
       "2     ARG_73_2018.txt          ARG      73  2018   \n",
       "3     JOR_73_2018.txt          JOR      73  2018   \n",
       "4     SWE_73_2018.txt          SWE      73  2018   \n",
       "...               ...          ...     ...   ...   \n",
       "8088  LIE_69_2014.txt          LIE      69  2014   \n",
       "8089  AZE_69_2014.txt          AZE      69  2014   \n",
       "8090  GRC_69_2014.txt          GRC      69  2014   \n",
       "8091  ISL_69_2014.txt          ISL      69  2014   \n",
       "8092  HUN_69_2014.txt          HUN      69  2014   \n",
       "\n",
       "                                                   text  \n",
       "0     Let me begin by congratulating Ms. María Ferna...  \n",
       "1     On my own behalf and on behalf of my country, ...  \n",
       "2     I would like to congratulate the President on ...  \n",
       "3     It is an honour to take part in the general de...  \n",
       "4     Just a bit more than a week ago, we honoured t...  \n",
       "...                                                 ...  \n",
       "8088  This has been an \\nenormously difficult year f...  \n",
       "8089  At the outset, \\nI would like to congratulate ...  \n",
       "8090  This sixty-ninth session of the General Assemb...  \n",
       "8091  Next year we will \\ncelebrate the seventieth a...  \n",
       "8092  “If you seek peace, prepare for war.” Those ar...  \n",
       "\n",
       "[8093 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ungdc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data to train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_text, test_text = train_test_split(ungdc_df['text'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save them to local repo as csv\n",
    "train_text.to_frame().to_csv(r'train_text_ungdc', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text.to_frame().to_csv(r'test_text_ungdc', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following model training process is conducted in Google Colab. It is too large to use the whole dataset, let us try only using texts from 2000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>country_code</th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6053</td>\n",
       "      <td>SAU_55_2000.txt</td>\n",
       "      <td>SAU</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "      <td>It\\ngives me pleasure at the outset of the fif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5938</td>\n",
       "      <td>AZE_55_2000.txt</td>\n",
       "      <td>AZE</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "      <td>Mr.\\nPresident, allow me first of all to congr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5937</td>\n",
       "      <td>GRC_55_2000.txt</td>\n",
       "      <td>GRC</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "      <td>I express my sincere\\ncongratulations to the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5936</td>\n",
       "      <td>VEN_55_2000.txt</td>\n",
       "      <td>VEN</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "      <td>I\\nagain extend our congratulations to the Pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5935</td>\n",
       "      <td>LIE_55_2000.txt</td>\n",
       "      <td>LIE</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "      <td>Allow me to begin my\\nremarks by congratulatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>MWI_73_2018.txt</td>\n",
       "      <td>MWI</td>\n",
       "      <td>73</td>\n",
       "      <td>2018</td>\n",
       "      <td>The General Assembly is a representation of hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>LCA_73_2018.txt</td>\n",
       "      <td>LCA</td>\n",
       "      <td>73</td>\n",
       "      <td>2018</td>\n",
       "      <td>Allow me to begin by congratulating the Presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>BEN_73_2018.txt</td>\n",
       "      <td>BEN</td>\n",
       "      <td>73</td>\n",
       "      <td>2018</td>\n",
       "      <td>I  have the honour to deliver the following st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>ROU_73_2018.txt</td>\n",
       "      <td>ROU</td>\n",
       "      <td>73</td>\n",
       "      <td>2018</td>\n",
       "      <td>I am  particularly honoured to address this ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BRB_73_2018.txt</td>\n",
       "      <td>BRB</td>\n",
       "      <td>73</td>\n",
       "      <td>2018</td>\n",
       "      <td>Let me begin by congratulating Ms. María Ferna...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3634 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename country_code session  year  \\\n",
       "6053  SAU_55_2000.txt          SAU      55  2000   \n",
       "5938  AZE_55_2000.txt          AZE      55  2000   \n",
       "5937  GRC_55_2000.txt          GRC      55  2000   \n",
       "5936  VEN_55_2000.txt          VEN      55  2000   \n",
       "5935  LIE_55_2000.txt          LIE      55  2000   \n",
       "...               ...          ...     ...   ...   \n",
       "127   MWI_73_2018.txt          MWI      73  2018   \n",
       "126   LCA_73_2018.txt          LCA      73  2018   \n",
       "125   BEN_73_2018.txt          BEN      73  2018   \n",
       "123   ROU_73_2018.txt          ROU      73  2018   \n",
       "0     BRB_73_2018.txt          BRB      73  2018   \n",
       "\n",
       "                                                   text  \n",
       "6053  It\\ngives me pleasure at the outset of the fif...  \n",
       "5938  Mr.\\nPresident, allow me first of all to congr...  \n",
       "5937  I express my sincere\\ncongratulations to the P...  \n",
       "5936  I\\nagain extend our congratulations to the Pre...  \n",
       "5935  Allow me to begin my\\nremarks by congratulatin...  \n",
       "...                                                 ...  \n",
       "127   The General Assembly is a representation of hu...  \n",
       "126   Allow me to begin by congratulating the Presid...  \n",
       "125   I  have the honour to deliver the following st...  \n",
       "123   I am  particularly honoured to address this ye...  \n",
       "0     Let me begin by congratulating Ms. María Ferna...  \n",
       "\n",
       "[3634 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ungdc_2000_df = ungdc_df.loc[ungdc_df['year'].astype('int') >= 2000]\n",
    "ungdc_2000_df = ungdc_2000_df.sort_values(by='year')\n",
    "ungdc_2000_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>country_code</th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6053</td>\n",
       "      <td>SAU_55_2000.txt</td>\n",
       "      <td>SAU</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "      <td>It gives me pleasure at the outset of the fift...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5938</td>\n",
       "      <td>AZE_55_2000.txt</td>\n",
       "      <td>AZE</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "      <td>Mr. President, allow me first of all to congra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5937</td>\n",
       "      <td>GRC_55_2000.txt</td>\n",
       "      <td>GRC</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "      <td>I express my sincere congratulations to the Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5936</td>\n",
       "      <td>VEN_55_2000.txt</td>\n",
       "      <td>VEN</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "      <td>I again extend our congratulations to the Pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5935</td>\n",
       "      <td>LIE_55_2000.txt</td>\n",
       "      <td>LIE</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "      <td>Allow me to begin my remarks by congratulating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>MWI_73_2018.txt</td>\n",
       "      <td>MWI</td>\n",
       "      <td>73</td>\n",
       "      <td>2018</td>\n",
       "      <td>The General Assembly is a representation of hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>LCA_73_2018.txt</td>\n",
       "      <td>LCA</td>\n",
       "      <td>73</td>\n",
       "      <td>2018</td>\n",
       "      <td>Allow me to begin by congratulating the Presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>BEN_73_2018.txt</td>\n",
       "      <td>BEN</td>\n",
       "      <td>73</td>\n",
       "      <td>2018</td>\n",
       "      <td>I  have the honour to deliver the following st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>ROU_73_2018.txt</td>\n",
       "      <td>ROU</td>\n",
       "      <td>73</td>\n",
       "      <td>2018</td>\n",
       "      <td>I am  particularly honoured to address this ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BRB_73_2018.txt</td>\n",
       "      <td>BRB</td>\n",
       "      <td>73</td>\n",
       "      <td>2018</td>\n",
       "      <td>Let me begin by congratulating Ms. María Ferna...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3634 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename country_code session  year  \\\n",
       "6053  SAU_55_2000.txt          SAU      55  2000   \n",
       "5938  AZE_55_2000.txt          AZE      55  2000   \n",
       "5937  GRC_55_2000.txt          GRC      55  2000   \n",
       "5936  VEN_55_2000.txt          VEN      55  2000   \n",
       "5935  LIE_55_2000.txt          LIE      55  2000   \n",
       "...               ...          ...     ...   ...   \n",
       "127   MWI_73_2018.txt          MWI      73  2018   \n",
       "126   LCA_73_2018.txt          LCA      73  2018   \n",
       "125   BEN_73_2018.txt          BEN      73  2018   \n",
       "123   ROU_73_2018.txt          ROU      73  2018   \n",
       "0     BRB_73_2018.txt          BRB      73  2018   \n",
       "\n",
       "                                                   text  \n",
       "6053  It gives me pleasure at the outset of the fift...  \n",
       "5938  Mr. President, allow me first of all to congra...  \n",
       "5937  I express my sincere congratulations to the Pr...  \n",
       "5936  I again extend our congratulations to the Pres...  \n",
       "5935  Allow me to begin my remarks by congratulating...  \n",
       "...                                                 ...  \n",
       "127   The General Assembly is a representation of hu...  \n",
       "126   Allow me to begin by congratulating the Presid...  \n",
       "125   I  have the honour to deliver the following st...  \n",
       "123   I am  particularly honoured to address this ye...  \n",
       "0     Let me begin by congratulating Ms. María Ferna...  \n",
       "\n",
       "[3634 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in ungdc_2000_df.iterrows():\n",
    "    temp = row['text']\n",
    "    temp = re.sub(r\"\\n\", \" \", temp)\n",
    "    row['text'] = temp\n",
    "\n",
    "ungdc_2000_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data to train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_text, test_text = train_test_split(ungdc_2000_df['text'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save them to local repo as csv\n",
    "train_text.to_frame().to_csv(r'train_text_ungdc2000', header=None, index=None, sep=' ', mode='a')\n",
    "test_text.to_frame().to_csv(r'test_text_ungdc2000', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train the model using Google Colab. The google colab notebook can be seen here [My google colab notebook](https://colab.research.google.com/drive/1VYVadCwQX3RU1cPIKcYHsP8dy7OPCI_g#scrollTo=L5bjXfZhuKOj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the pretrained model in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "tokenizer_ungdc = AutoTokenizer.from_pretrained(\"output_gpt_ungdc2000\")\n",
    "model_ungdc = AutoModelWithLMHead.from_pretrained(\"output_gpt_ungdc2000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discovering topics using text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate change is a major challenge for the world. The world is facing a new challenge, one that is not only global, but also global in scope. The United Nations is the only global organization that can effectively address the challenges of climate change.\"\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Climate change is\"\n",
    "\n",
    "input = tokenizer_ungdc.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_ungdc.generate(input, max_length=50, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_ungdc.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public health is the most important  priority of the United Nations. We must ensure that  the United Nations is able to respond to the needs of  the most vulnerable countries.   The United Nations is the only Organization that  can provide the necessary support to the most vulnerable  countries. The United Nations is the only  Organization that can provide the necessary support to  the most vulnerable countries.   The United Nations is the only Organization that can  provide the necessary support to the most vulnerable\"\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Public health is\"\n",
    "\n",
    "input = tokenizer_ungdc.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_ungdc.generate(input, max_length=100, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_ungdc.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terrorism is a threat to international peace and security. It is a threat to the stability of the region and to the stability of the world. It is a threat to the stability of the world. It is a threat to the stability of the world. It is a threat to the stability of the world. It is a threat to the stability of the world. It is a threat to the stability of the world. It is a threat to the stability of the world. It is a threat\"\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Terrorism is\"\n",
    "\n",
    "input = tokenizer_ungdc.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_ungdc.generate(input, max_length=100, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_ungdc.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Syrian conflict has been a source of great concern to the international community. The Syrian people have suffered a terrible loss of life and have suffered a great loss of property. The Syrian people have suffered a great loss of life and have suffered a great\"\n"
     ]
    }
   ],
   "source": [
    "sequence = \"The Syrian conflict has\"\n",
    "\n",
    "input = tokenizer_ungdc.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_ungdc.generate(input, max_length=50, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_ungdc.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The relationship between North and South Korea has been a source of great concern to the international community. The recent nuclear tests of the United States and the Russian Federation have demonstrated that the United States and Russia are not only adversaries, but also partners in the fight against terrorism. The United States and Russia have been at odds for decades, and the United States and Russia have been at odds for decades. The United States and Russia have been at odds for decades, and the United States and Russia have been at\"\n"
     ]
    }
   ],
   "source": [
    "sequence = \"The relationship between North and South Korea has\"\n",
    "\n",
    "input = tokenizer_ungdc.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_ungdc.generate(input, max_length=100, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_ungdc.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The conflicts in Crimea has been a source of great concern to the international community. The situation in the region has become a source of concern to the international community. The situation in the Democratic Republic of the Congo has been a source of concern to the international community. The situation in the Democratic Republic of the Congo has been a source of concern to the international community. The situation in the Democratic Republic of the Congo has been a source of concern to the international community. The situation in the Democratic Republic of\"\n"
     ]
    }
   ],
   "source": [
    "sequence = \"The conflicts in Crimea has\"\n",
    "\n",
    "input = tokenizer_ungdc.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_ungdc.generate(input, max_length=100, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_ungdc.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China is a country that has been a member of the United Nations for more than half a century. We are proud to be a member of the United Nations. We are proud to be a member of the United Nations. We are proud to be a member of the United Nations. We are proud to be a member of the United Nations. We are proud to be a member of the United Nations. We are proud to be a member of the United Nations. We are proud to be a member\"\n"
     ]
    }
   ],
   "source": [
    "sequence = \"China is\"\n",
    "\n",
    "input = tokenizer_ungdc.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_ungdc.generate(input, max_length=100, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_ungdc.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
